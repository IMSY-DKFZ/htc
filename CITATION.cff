cff-version: 1.2.0
message: "If you use the htc framework, please consider citing our 2022 publication in the Medical Image Analysis journal."
authors:
  - family-names: "Sellner"
    given-names: "Jan"
  - family-names: "Seidlitz"
    given-names: "Silvia"
title: "Hyperspectral Tissue Classification"
url: "https://github.com/IMSY-DKFZ/htc"
preferred-citation:
  type: article
  authors:
    - family-names: "Seidlitz"
      given-names: "Silvia"
    - family-names: "Sellner"
      given-names: "Jan"
    - family-names: "Odenthal"
      given-names: "Jan"
    - family-names: "Özdemir"
      given-names: "Berkin"
    - family-names: "Studier-Fischer"
      given-names: "Alexander"
    - family-names: "Knödler"
      given-names: "Samuel"
    - family-names: "Ayala"
      given-names: "Leonardo"
    - family-names: "Adler"
      given-names: "Tim J."
    - family-names: "Kenngott"
      given-names: "Hannes G."
    - family-names: "Tizabi"
      given-names: "Minu"
    - family-names: "Wagner"
      given-names: "Martin"
    - family-names: "Nickel"
      given-names: "Felix"
    - family-names: "Müller-Stich"
      given-names: "Beat P."
    - family-names: "Maier-Hein"
      given-names: "Lena"
  title: "Robust deep learning-based semantic organ segmentation in hyperspectral images"
  journal: "Medical Image Analysis"
  volume: 80
  pages: 102488
  year: 2022
  issn: "1361-8415"
  doi: "10.1016/j.media.2022.102488"
  url: "https://www.sciencedirect.com/science/article/pii/S1361841522001359"
  keywords:
    - "Surgical data science"
    - "Open surgery"
    - "Hyperspectral imaging"
    - "Organ segmentation"
    - "Semantic scene segmentation"
    - "Deep learning"
  abstract: "Semantic image segmentation is an important prerequisite for context-awareness and autonomous robotics in surgery. The state of the art has focused on conventional RGB video data acquired during minimally invasive surgery, but full-scene semantic segmentation based on spectral imaging data and obtained during open surgery has received almost no attention to date. To address this gap in the literature, we are investigating the following research questions based on hyperspectral imaging (HSI) data of pigs acquired in an open surgery setting: (1) What is an adequate representation of HSI data for neural network-based fully automated organ segmentation, especially with respect to the spatial granularity of the data (pixels vs. superpixels vs. patches vs. full images)? (2) Is there a benefit of using HSI data compared to other modalities, namely RGB data and processed HSI data (e.g. tissue parameters like oxygenation), when performing semantic organ segmentation? According to a comprehensive validation study based on 506 HSI images from 20 pigs, annotated with a total of 19 classes, deep learning-based segmentation performance increases — consistently across modalities — with the spatial context of the input data. Unprocessed HSI data offers an advantage over RGB data or processed data from the camera provider, with the advantage increasing with decreasing size of the input to the neural network. Maximum performance (HSI applied to whole images) yielded a mean DSC of 0.90 ((standard deviation (SD)) 0.04), which is in the range of the inter-rater variability (DSC of 0.89 ((standard deviation (SD)) 0.07)). We conclude that HSI could become a powerful image modality for fully-automatic surgical scene understanding with many advantages over traditional imaging, including the ability to recover additional functional tissue information. Our code and pre-trained models are available at https://github.com/IMSY-DKFZ/htc."
