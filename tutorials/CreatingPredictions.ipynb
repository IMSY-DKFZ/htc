{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88283e85-2a29-4816-b5ec-a8d15613eb1c",
   "metadata": {},
   "source": [
    "# Creating Predictions\n",
    "If you have some HSI images and want to get predictions from one of our pretrained models (or your own models), then we covered you in this notebook. Predictions can be computed based on a folder with HSI images and the `htc inference` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f50cc1a7-971b-40cd-ba89-43c2835257e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from htc import Config, LabelMapping, decompress_file, settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04bfa34-330b-47f7-b032-290db9e4383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = settings.data_dirs[\"HeiPorSPECTRAL\"]\n",
    "output_dir = settings.results_dir / \"predictions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c10e8-cca8-46f9-91e1-3a9f02d55103",
   "metadata": {},
   "source": [
    "> Note: If you want to use your own data and it does not fit into the default structure (e.g. because you have non-Tivita images), they you need to write your [own DataPath class](./CustomDataPath.md) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1997912-0a42-45e2-b170-d2774a4069ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "!htc inference --input-dir \"$data_dir/subjects/P086/2021_04_15_09_22_02\" --output-dir $output_dir --model image --run-folder \"2022-02-03_22-58-44_generated_default_model_comparison\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d11729",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _exit_code == 0, f\"Inference was not successful:\\n{output.show()}\"  # noqa: F821"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a82bc5e-b48b-4aa5-9dbc-ac300e6724f4",
   "metadata": {},
   "source": [
    "This command searches for all HSI images in the given input directory, computes a prediction using the specified trained model (will also be downloaded if not available) and stores the result in the given output directory. You can use any of the pretrained models here.\n",
    "\n",
    "In this example case, there is only one output image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "059251ab-f15f-436b-bca5-deeac44a29ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/ssd_8tb/htc/results_test/predictions/image'),\n",
       " PosixPath('/mnt/ssd_8tb/htc/results_test/predictions/image/2022-02-03_22-58-44_generated_default_model_comparison'),\n",
       " PosixPath('/mnt/ssd_8tb/htc/results_test/predictions/image/2022-02-03_22-58-44_generated_default_model_comparison/predictions'),\n",
       " PosixPath('/mnt/ssd_8tb/htc/results_test/predictions/image/2022-02-03_22-58-44_generated_default_model_comparison/predictions/0202-00118#2021_04_15_09_22_02.blosc'),\n",
       " PosixPath('/mnt/ssd_8tb/htc/results_test/predictions/image/2022-02-03_22-58-44_generated_default_model_comparison/predictions/0202-00118#2021_04_15_09_22_02.html'),\n",
       " PosixPath('/mnt/ssd_8tb/htc/results_test/predictions/image/2022-02-03_22-58-44_generated_default_model_comparison/predictions/config.json')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(output_dir.rglob(\"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14db9ec1-c7c9-493e-b4af-b3d77f90e22e",
   "metadata": {},
   "source": [
    "Per default, this includes the predicted labels (stored in the blosc file), a visualization of the prediction (HTML file) and the config which was used for computing the predictions (which again is based on the config of the trained model). You can open the HTML file directly with any browser. The labels can be read with the `decompress_file()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9a00b0-7bf0-4237-ae5d-2840ecc38cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 12, 12,  0],\n",
       "       [ 0,  0,  0, ..., 12, 12,  0],\n",
       "       [ 0,  0,  0, ..., 12, 12, 12],\n",
       "       ...,\n",
       "       [ 5,  5,  5, ...,  4,  4,  4],\n",
       "       [ 5,  5,  5, ...,  4,  4,  4],\n",
       "       [ 5,  5,  5, ...,  4,  4,  4]], shape=(480, 640))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = decompress_file(sorted(output_dir.rglob(\"*.blosc\"))[0])\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b0c7e-89fe-403e-99d8-8d349ff24443",
   "metadata": {},
   "source": [
    "The config can, for example, be used to recover the original label names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45244a8c-281f-4a29-b1ac-8f304877c581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background: 55533 pixels\n",
      "liver: 26716 pixels\n",
      "colon: 97583 pixels\n",
      "small_bowel: 1090 pixels\n",
      "stomach: 37650 pixels\n",
      "spleen: 42066 pixels\n",
      "omentum: 9682 pixels\n",
      "peritoneum: 20736 pixels\n",
      "skin: 5815 pixels\n",
      "fat_subcutaneous: 10329 pixels\n"
     ]
    }
   ],
   "source": [
    "config = Config(sorted(output_dir.rglob(\"config.json\"))[0])\n",
    "mapping = LabelMapping.from_config(config)\n",
    "\n",
    "for l, c in zip(*np.unique(labels, return_counts=True), strict=True):\n",
    "    print(f\"{mapping.index_to_name(l)}: {c} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b30945-dadb-4cf6-9036-b9aee922ad3d",
   "metadata": {},
   "source": [
    "> Note: if you need the softmax values instead of the label indices of the prediction, add the `--predictions-type softmax` switch to `htc inference`. However, be aware that this requires much more disk space (around 17 MiB instead of 2 KiB per image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
